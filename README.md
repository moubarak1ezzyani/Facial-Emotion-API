# üòê Facial Emotion API

## üìÑ Contexte du Projet

Ce projet est un prototype d'API REST d√©velopp√© pour une startup d'analyse UX. Il combine **Vision par Ordinateur** et **Deep Learning** pour analyser les √©motions faciales en temps r√©el et stocker les r√©sultats pour des √©tudes statistiques.

L'application expose une API performante (FastAPI asynchrone) capable de d√©tecter un visage, classifier son √©motion parmi 7 cat√©gories (*Happy, Sad, Angry, Surprise, Neutral, Fear, Disgusted*) et archiver la donn√©e.

## ‚öôÔ∏è Architecture Technique

Le pipeline de traitement suit ces √©tapes rigoureuses :

1. **R√©ception** : L'API re√ßoit une image via l'endpoint `/predict_emotion`.
2. **D√©tection (OpenCV)** : Le classifieur *Haar Cascade* isole le visage.
3. **Normalisation** : Recadrage, conversion en niveaux de gris, redimensionnement (48x48px) et mise √† l'√©chelle [0-1].
4. **Inf√©rence (CNN)** : Le mod√®le TensorFlow (`.keras`) pr√©dit l'√©motion et le score de confiance.
5. **Persistance (SQLAlchemy Async)** : Enregistrement non-bloquant dans PostgreSQL.

---

## üìÇ Structure du Projet

```bash
‚îú‚îÄ‚îÄ create_tables.py                     # Script d'initialisation de la base de donn√©es (SQLAlchemy)
‚îú‚îÄ‚îÄ DetectFaces.py                       # Script autonome pour tester la d√©tection (OpenCV + CNN)
‚îú‚îÄ‚îÄ haarcascade-frontalface-default.xml  # Mod√®le OpenCV pour la d√©tection de visages
‚îú‚îÄ‚îÄ main.py                              # Application principale (API FastAPI)
‚îú‚îÄ‚îÄ MainML.ipynb                         # Notebook Jupyter d'entra√Ænement du mod√®le
‚îú‚îÄ‚îÄ my_model_emotion_detection.keras     # Mod√®le CNN entra√Æn√© et sauvegard√©
‚îú‚îÄ‚îÄ requirements.txt                     # Liste des librairies (tensorflow, fastapi, opencv...)
‚îî‚îÄ‚îÄ test_unitaire.py                     # Tests pour valider le chargement du mod√®le et l'API
```

---

## üöÄ Installation et Configuration

### 1. Pr√©-requis

* Python 3.9+
* PostgreSQL install√© et service actif.

### 2. Installation

Cloner le d√©p√¥t et installer les librairies :

```bash
git clone https://github.com/votre-user/Facial-Emotion-API.git
pip install -r requirements.txt

```

### 3. Configuration de la Base de Donn√©es

Cr√©ez un fichier `.env` √† la racine du projet pour vos variables d'environnement (s√©curit√©) :

```env
DB_USER=postgres
DB_PASS=votre_mot_de_passe
DB_HOST=localhost
DB_NAME=emotion_db

```

Initialisez les tables dans la base de donn√©es avec le script d√©di√© :

```bash
python create_tables.py

```

*(Cela cr√©era la table `EmotionTable` via SQLAlchemy).*

---

## üíª Utilisation

### Lancer l'API (Serveur)

D√©marrer le serveur Uvicorn avec rechargement automatique :

```bash
uvicorn main:app --reload

```

L'API sera accessible sur : `http://127.0.0.1:8000`

### Tester avec le script autonome

Si vous souhaitez tester la d√©tection et la pr√©diction sur une image locale sans passer par le serveur :

```bash
python DetectFaces.py

```

*(Assurez-vous de modifier le chemin `image_path` dans le fichier avant).*

---

## üì° Documentation des Endpoints

Une documentation interactive (Swagger UI) est disponible automatiquement sur `http://127.0.0.1:8000/docs`.

### 1Ô∏è‚É£ `POST /predict_emotion`

Analyse une image envoy√©e par l'utilisateur.

* **Input** : Fichier image (`UploadFile`).
* **Processus** : D√©tection -> Pr√©diction -> Sauvegarde DB.
* **Output (JSON)** :
```json
{
  "face_detected": true,
  "emotion": "happy",
  "confidence": 0.98,
  "processing_time": "0.04s"
}

```



### 2Ô∏è‚É£ `GET /history`

R√©cup√®re l'historique des analyses stock√©es en base.

* **Output** : Liste des entr√©es (ID, Emotion, Confiance, Date).

---

## ‚úÖ Qualit√© du Code & Tests

Le projet int√®gre des tests unitaires pour garantir la robustesse du mod√®le.

**Ex√©cuter les tests :**

```bash
pytest test_unitaire.py

```

**Couverture des tests :**

* `test_model_save_and_load` : V√©rifie l'int√©grit√© de la sauvegarde/chargement du mod√®le `.keras`.
* `test_prediction_format` : V√©rifie que le mod√®le renvoie bien un tenseur de forme `(1, 7)`.

---

## üß† D√©tails du Mod√®le (CNN)

* **Entra√Ænement** : Notebook `MainML.ipynb`.
* **Input** : Images 48x48 pixels, Grayscale (1 canal).
* **Classes (7)** : `Angry`, `Disgusted`, `Fearful`, `Happy`, `Neutral`, `Sad`, `Surprised`.
* **Performance** : Mod√®le optimis√© pour la rapidit√© d'inf√©rence (convient au temps r√©el).
